{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66ebdade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65863bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = [json.loads(line) for line in file]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2eedf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"rl-sentence-compression/data/train-data/gigaword/train.jsonl\"\n",
    "val_path = \"rl-sentence-compression/data/train-data/gigaword/val.jsonl\"\n",
    "test_path = \"rl-sentence-compression/data/test-data/gigaword.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e08c0417",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_data(train_path)\n",
    "val_data = load_data(val_path)\n",
    "test_data = load_data(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e84c4da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n",
      "189651\n",
      "1951\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(val_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf4ab264",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[0:4000]\n",
    "val_data   = val_data[0:4000]\n",
    "test_data = test_data[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3abe43bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n",
      "4000\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(val_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ec21e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_id(data):\n",
    "    updated_data = []\n",
    "    for item in data:\n",
    "        updated_item = {key:value for key,value in item.items() if key != \"id\"}\n",
    "        updated_data.append(updated_item)\n",
    "    return updated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "529139a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = remove_id(train_data)\n",
    "test_data = remove_id(test_data)\n",
    "val_data = remove_id(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99a2005d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_data)\n",
    "val_df   = pd.DataFrame(val_data)\n",
    "test_df  = pd.DataFrame(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e65c7306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>australia 's current account deficit shrunk by...</td>\n",
       "      <td>australian current account deficit narrows sha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>at least two people were killed in a suspected...</td>\n",
       "      <td>at least two dead in southern philippines blast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>australian shares closed down #.# percent mond...</td>\n",
       "      <td>australian stocks close down #.# percent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>south korea 's nuclear envoy kim sook urged no...</td>\n",
       "      <td>envoy urges north korea to restart nuclear dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>south korea on monday announced sweeping tax r...</td>\n",
       "      <td>skorea announces tax cuts to stimulate economy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  australia 's current account deficit shrunk by...   \n",
       "1  at least two people were killed in a suspected...   \n",
       "2  australian shares closed down #.# percent mond...   \n",
       "3  south korea 's nuclear envoy kim sook urged no...   \n",
       "4  south korea on monday announced sweeping tax r...   \n",
       "\n",
       "                                             summary  \n",
       "0  australian current account deficit narrows sha...  \n",
       "1    at least two dead in southern philippines blast  \n",
       "2           australian stocks close down #.# percent  \n",
       "3  envoy urges north korea to restart nuclear dis...  \n",
       "4     skorea announces tax cuts to stimulate economy  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b970665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.rename(columns = {'summaries':'summary'}, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e40445d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>japan 's nec corp. and UNK computer corp. of t...</td>\n",
       "      <td>nec UNK in computer sales tie-up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the sri lankan government on wednesday announc...</td>\n",
       "      <td>sri lanka closes schools as war escalates</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  japan 's nec corp. and UNK computer corp. of t...   \n",
       "1  the sri lankan government on wednesday announc...   \n",
       "\n",
       "                                     summary  \n",
       "0           nec UNK in computer sales tie-up  \n",
       "1  sri lanka closes schools as war escalates  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(test_df['text'][0]))\n",
    "print(type(test_df['summary'][0]))\n",
    "test_df['summary'] = test_df['summary'].str[0].astype(str)\n",
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9801e850",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_integer(value):\n",
    "    try:\n",
    "        int(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24c70b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in train_df.iterrows():\n",
    "    if any(is_integer(value) for value in row):\n",
    "        train_df.drop(index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "719fedba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in val_df.iterrows():\n",
    "    if any(is_integer(value) for value in row):\n",
    "        val_df.drop(index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a871b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in test_df.iterrows():\n",
    "    if any(is_integer(value) for value in row):\n",
    "        test_df.drop(index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7421dbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.reset_index(drop=True, inplace=True)\n",
    "val_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36036035",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.head(2000)\n",
    "val_df   = val_df.head(2000)\n",
    "test_df  = test_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da0c137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: Clean text data\n",
    "def clean_text(df):\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].str.lower()\n",
    "        df[col] = df[col].str.lstrip().str.rstrip()\n",
    "        df[col] = df[col].str.replace(r'[^\\w\\s]+', '')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfe481d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = clean_text(train_df)\n",
    "val_df = clean_text(val_df)\n",
    "test_df = clean_text(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9ece0b",
   "metadata": {},
   "source": [
    "for col in train_df.columns:\n",
    "    train_df[col] = train_df[col].str.lower()\n",
    "for column in train_df.columns:\n",
    "    train_df[column] = train_df[column].str.lstrip().str.rstrip()\n",
    "for column in train_df.columns:\n",
    "    train_df[column] = train_df[column].str.replace(r'[^\\w\\s]+', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f027ca",
   "metadata": {},
   "source": [
    "for col in val_df.columns:\n",
    "    val_df[col] = val_df[col].str.lower()\n",
    "for column in val_df.columns:\n",
    "    val_df[column] = val_df[column].str.lstrip().str.rstrip()\n",
    "for column in val_df.columns:\n",
    "    val_df[column] = val_df[column].str.replace(r'[^\\w\\s]+', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0fe0c6",
   "metadata": {},
   "source": [
    "for col in test_df.columns:\n",
    "    test_df[col] = test_df[col].str.lower()\n",
    "for column in test_df.columns:\n",
    "    test_df[column] = test_df[column].str.lstrip().str.rstrip()\n",
    "for column in test_df.columns:\n",
    "    test_df[column] = test_df[column].str.replace(r'[^\\w\\s]+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9111876",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dropout, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4197b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum sentence length (word count)\n",
    "max_len_word = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b0f1ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BERT tokenizer\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cdbe836c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize text and summary data\n",
    "def tokenize_text(text, max_length):\n",
    "    tokens = tokenizer(text, max_length=max_length, padding=\"max_length\", \n",
    "                       truncation=True, return_tensors='pt')\n",
    "    return tokens['input_ids'], tokens['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5add08df",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train_input_ids, text_train_mask = tokenize_text(train_df['text'], \n",
    "                                                      max_len_word)\n",
    "text_val_input_ids, text_val_mask = tokenize_text(val_df['text'], \n",
    "                                                  max_len_word)\n",
    "text_test_input_ids, text_test_mask = tokenize_text(test_df['text'], \n",
    "                                                    max_len_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931e4e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_summary(summary, max_length):\n",
    "    encoding = tokenizer(summary,max_length=max_length, padding=\"max_length\",\n",
    "                         truncation=True, return_tensors='pt',\n",
    "                         add_special_tokens=True,\n",
    "                         )\n",
    "    input_ids = encoding['input_ids']\n",
    "    attention_mask = encoding['attention_mask']\n",
    "    return input_ids, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62de2215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode summary data\n",
    "summary_train_input_ids, summary_train_mask = tokenize_summary(train_df['summary'], max_len_word)\n",
    "summary_val_input_ids, summary_val_mask = tokenize_summary(val_df['summary'], max_len_word)\n",
    "summary_test_input_ids, summary_test_mask = tokenize_summary(test_df['summary'], max_len_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b96c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentences(sentences):\n",
    "    encoding = tokenizer.batch_encode_plus(sentences,\n",
    "                                           padding=True,\n",
    "                                           truncation=True,\n",
    "                                           return_tensors='pt',\n",
    "                                           add_special_tokens=True)\n",
    "    input_ids = encoding['input_ids']\n",
    "    attention_mask = encoding['attention_mask']\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        word_embeddings = outputs.last_hidden_state \n",
    "    return word_embeddings, input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a9d415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode text data\n",
    "text_embeddings_train_bert,train_ids = encode_sentences(train_df['text'])\n",
    "text_embeddings_val_bert,val_ids = encode_sentences(val_df['text'])\n",
    "text_embeddings_test_bert,test_ids = encode_sentences(test_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1309f0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode summary data\n",
    "summary_embeddings_train_bert, summay_train_id = encode_sentences(train_df['summary'])\n",
    "summary_embeddings_val_bert, summary_val_id = encode_sentences(val_df['summary'])\n",
    "summary_embeddings_test_bert, summary_test_id= encode_sentences(test_df['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5b1467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad e sequences to ensure consistent length\n",
    "summary_embeddings_train_bert = pad_sequences(summary_embeddings_train_bert, maxlen=max_sequence_length, padding='post')\n",
    "summary_embeddings_val_bert = pad_sequences(summary_embeddings_val_bert, maxlen=max_sequence_length, padding='post')\n",
    "summary_embeddings_test_bert = pad_sequences(summary_embeddings_test_bert, maxlen=max_sequence_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c736bc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine text and summary embeddings for training\n",
    "combined_train_input = np.concatenate((text_embeddings_train_bert, summary_embeddings_train_bert), axis=1)\n",
    "combined_val_input = np.concatenate((text_embeddings_val_bert, summary_embeddings_val_bert), axis=1)\n",
    "combined_test_input = np.concatenate((text_embeddings_test_bert, summary_embeddings_test_bert), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e71806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input shape for combined input\n",
    "combined_input_shape = (max_sequence_length, 768 * 2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae83782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input layer for combined input\n",
    "combined_input = Input(shape=combined_input_shape)\n",
    "combined_embeddings = combined_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1351703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architecture\n",
    "num_bert_layers = 12\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631d0e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = Input(shape=(max_len_word,), dtype='int32')\n",
    "input_summary = Input(shape=(max_len_word,), dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d51efeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3810ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embeddings = merged_embeddings = Concatenate(axis=1)([text_embeddings, summary_embeddings])rt_model(input_text)[1]\n",
    "summary_embeddings = bert_model(input_summary)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b9b563",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_embeddings = Concatenate(axis=1)([text_embeddings, summary_embeddings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a112216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(num_bert_layers):\n",
    "    merged_embeddings = Dropout(dropout_rate)(merged_embeddings)\n",
    "    for _ in range(3):\n",
    "        merged_embeddings = Dense(merged_embeddings.shape[-1], activation=\"relu\")(merged_embeddings)\n",
    "        merged_embeddings = Dropout(dropout_rate)(merged_embeddings)\n",
    "        merged_embeddings = Dense(merged_embeddings.shape[-1])(merged_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d6e1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output la# Compile the model\n",
    "model = Model(inputs=[input_text, input_summary], outputs=output)\n",
    "output = Dense(1, activation='sigmoid')(merged_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d184f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model = Model(inputs=[input_text, input_summary], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85398cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(optimizer=optimizer, loss=binary_crossentropy, \n",
    "#              metrics=[binary_accuracy])\n",
    "model.compile(optimizer=optimizer, loss=binary_crossentropy, \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d587d690",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1321f3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "model.fit([text_train_input, summary_train_input], text_train_mask, \n",
    "          validation_data=([text_val_input, summary_val_input], text_val_mask), \n",
    "          epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58032a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "# Evaluate the model on test data\n",
    "loss, accuracy = model.evaluate([text_test_input, summary_test_input], text_test_mask)\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d83eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_summary = model.predict([text_test_input, summary_test_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e27224",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_summaries = decode_summary(predicted_summary, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0ff478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary text for each sample\n",
    "for i, summary_text in enumerate(decoded_summaries):\n",
    "    print(f\"Sample {i+1} Summary: {summary_text} Len: {len(summary_text)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2ac167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6491947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and encode summary data\n",
    "summary_train_input, summary_train_mask = tokenize_text(train_df['summary'], max_len_word)\n",
    "summary_val_input, summary_val_mask = tokenize_text(val_df['summary'], max_len_word)\n",
    "summary_test_input, summary_test_mask = tokenize_text(test_df['summary'], max_len_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0313b546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode summary data\n",
    "summary_embeddings_train_bert, _ = encode_sentences(train_df['summary'])\n",
    "summary_embeddings_val_bert, _ = encode_sentences(val_df['summary'])\n",
    "summary_embeddings_test_bert, _ = encode_sentences(test_df['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb604f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the sequences to ensure consistent length\n",
    "summary_embeddings_train_bert = pad_sequences(summary_embeddings_train_bert, maxlen=max_sequence_length, padding='post')\n",
    "summary_embeddings_val_bert = pad_sequences(summary_embeddings_val_bert, maxlen=max_sequence_length, padding='post')\n",
    "summary_embeddings_test_bert = pad_sequences(summary_embeddings_test_bert, maxlen=max_sequence_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28f3259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine text and summary embeddings for training\n",
    "combined_train_input = np.concatenate((text_embeddings_train_bert, summary_embeddings_train_bert), axis=1)\n",
    "combined_val_input = np.concatenate((text_embeddings_val_bert, summary_embeddings_val_bert), axis=1)\n",
    "combined_test_input = np.concatenate((text_embeddings_test_bert, summary_embeddings_test_bert), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bb62f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input shape for combined input\n",
    "combined_input_shape = (max_sequence_length, 768 * 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98949887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input layer for combined input\n",
    "combined_input = Input(shape=combined_input_shape)\n",
    "combined_embeddings = combined_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9065b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model architecture for combined input\n",
    "num_bert_layers = 12\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bcc3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(num_bert_layers):\n",
    "    combined_embeddings = Dropout(dropout_rate)(combined_embeddings)\n",
    "    for _ in range(3):\n",
    "        combined_embeddings = Dense(combined_embeddings.shape[-1], activation=\"relu\")(combined_embeddings)\n",
    "        combined_embeddings = Dropout(dropout_rate)(combined_embeddings)\n",
    "        combined_embeddings = Dense(combined_embeddings.shape[-1])(combined_embeddings)\n",
    "        \n",
    "        # Add skip connection\n",
    "        combined_embeddings = combined_embeddings + combined_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875e987e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final feedforward layer with sigmoid activation\n",
    "combined_output = Dense(150, activation=\"sigmoid\")(combined_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53caf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_combined = Model(inputs=combined_input, outputs=combined_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4da9422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=1e-5, epsilon=1e-8)\n",
    "model_combined.compile(optimizer=optimizer, loss=binary_crossentropy, \n",
    "                       metrics=[binary_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b22d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_combined.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7bf943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with combined inputs\n",
    "model_combined.fit(combined_train_input, text_train_mask, \n",
    "                   validation_data=(combined_val_input, text_val_mask), \n",
    "                   epochs=10, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf584db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summaries for test data using the trained model\n",
    "combined_predicted_summary = model_combined.predict(combined_test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e3e6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the generated summaries\n",
    "def decode_combined_summary(embeddings, tokenizer):\n",
    "    decoded_summaries = []\n",
    "    for i in range(len(embeddings)):\n",
    "        summary_text = tokenizer.decode(embeddings[i], skip_special_tokens=True)\n",
    "        decoded_summaries.append(summary_text)\n",
    "    return decoded_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55d5465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'tokenizer' is your BERT tokenizer instance\n",
    "decoded_combined_summaries=decode_combined_summary(combined_predicted_summary,\n",
    "                                                   tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8d3ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary text for each sample\n",
    "for i, summary_text in enumerate(decoded_combined_summaries):\n",
    "    print(f\"Sample {i+1} Summary: {summary_text} Len: {len(summary_text)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40ee494",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153db5f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbc580c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2b4094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783e1eff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa617499",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
