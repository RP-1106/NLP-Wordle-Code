{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe62ca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0deb65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = [json.loads(line) for line in file]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abb90c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"rl-sentence-compression/data/train-data/gigaword/train.jsonl\"\n",
    "val_path = \"rl-sentence-compression/data/train-data/gigaword/val.jsonl\"\n",
    "test_path = \"rl-sentence-compression/data/test-data/gigaword.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3841cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_data(train_path)\n",
    "val_data = load_data(val_path)\n",
    "test_data = load_data(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6822296d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n",
      "189651\n",
      "1951\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(val_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dffebb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[0:10000]\n",
    "val_data   = val_data[0:10000]\n",
    "test_data = test_data[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "136e1dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(val_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86c79590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_id(data):\n",
    "    updated_data = []\n",
    "    for item in data:\n",
    "        updated_item = {key:value for key,value in item.items() if key != \"id\"}\n",
    "        updated_data.append(updated_item)\n",
    "    return updated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb156302",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = remove_id(train_data)\n",
    "test_data = remove_id(test_data)\n",
    "val_data = remove_id(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66a2995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_data)\n",
    "val_df   = pd.DataFrame(val_data)\n",
    "test_df  = pd.DataFrame(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef8d81c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>australia 's current account deficit shrunk by...</td>\n",
       "      <td>australian current account deficit narrows sha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>at least two people were killed in a suspected...</td>\n",
       "      <td>at least two dead in southern philippines blast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>australian shares closed down #.# percent mond...</td>\n",
       "      <td>australian stocks close down #.# percent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>south korea 's nuclear envoy kim sook urged no...</td>\n",
       "      <td>envoy urges north korea to restart nuclear dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>south korea on monday announced sweeping tax r...</td>\n",
       "      <td>skorea announces tax cuts to stimulate economy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  australia 's current account deficit shrunk by...   \n",
       "1  at least two people were killed in a suspected...   \n",
       "2  australian shares closed down #.# percent mond...   \n",
       "3  south korea 's nuclear envoy kim sook urged no...   \n",
       "4  south korea on monday announced sweeping tax r...   \n",
       "\n",
       "                                             summary  \n",
       "0  australian current account deficit narrows sha...  \n",
       "1    at least two dead in southern philippines blast  \n",
       "2           australian stocks close down #.# percent  \n",
       "3  envoy urges north korea to restart nuclear dis...  \n",
       "4     skorea announces tax cuts to stimulate economy  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c407cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.rename(columns = {'summaries':'summary'}, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d196196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>japan 's nec corp. and UNK computer corp. of t...</td>\n",
       "      <td>nec UNK in computer sales tie-up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the sri lankan government on wednesday announc...</td>\n",
       "      <td>sri lanka closes schools as war escalates</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  japan 's nec corp. and UNK computer corp. of t...   \n",
       "1  the sri lankan government on wednesday announc...   \n",
       "\n",
       "                                     summary  \n",
       "0           nec UNK in computer sales tie-up  \n",
       "1  sri lanka closes schools as war escalates  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(test_df['text'][0]))\n",
    "print(type(test_df['summary'][0]))\n",
    "test_df['summary'] = test_df['summary'].str[0].astype(str)\n",
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cfdaaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_integer(value):\n",
    "    try:\n",
    "        int(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d6c560a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in train_df.iterrows():\n",
    "    if any(is_integer(value) for value in row):\n",
    "        train_df.drop(index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad2bb64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in val_df.iterrows():\n",
    "    if any(is_integer(value) for value in row):\n",
    "        val_df.drop(index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf4498b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in test_df.iterrows():\n",
    "    if any(is_integer(value) for value in row):\n",
    "        test_df.drop(index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "435a0e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.reset_index(drop=True, inplace=True)\n",
    "val_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c05e2a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.head(2000)\n",
    "val_df   = val_df.head(2000)\n",
    "test_df  = test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d410b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: Clean text data\n",
    "def clean_text(df):\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].str.lower()\n",
    "        df[col] = df[col].str.lstrip().str.rstrip()\n",
    "        df[col] = df[col].str.replace(r'[^\\w\\s]+', '')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9204cd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rhea Pandita\\AppData\\Local\\Temp\\ipykernel_16592\\2171058854.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[col] = df[col].str.replace(r'[^\\w\\s]+', '')\n"
     ]
    }
   ],
   "source": [
    "train_df = clean_text(train_df)\n",
    "val_df = clean_text(val_df)\n",
    "test_df = clean_text(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "250d33dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8147738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum sentence length (word count)\n",
    "max_len_word = 100\n",
    "# Maximum wordpiece length\n",
    "max_wordpiece_len = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f63cc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "026a23eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2359a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2bdf09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode sentences with padding and truncation (improved for wordpiece handling)\n",
    "def encode_sentences(sentences):\n",
    "    encoding = tokenizer.batch_encode_plus(sentences,\n",
    "                                         padding='max_length',\n",
    "                                         truncation=True,\n",
    "                                         return_tensors='pt',\n",
    "                                         add_special_tokens=True)\n",
    "    input_ids = encoding['input_ids']\n",
    "    attention_mask = encoding['attention_mask']\n",
    "    \n",
    "    # Ensure correct handling of padding tokens\n",
    "    pad_token_id = tokenizer.pad_token_id\n",
    "    attention_mask[attention_mask == 0] = -100\n",
    "    \n",
    "    # Handle wordpiece truncation (assuming max_wordpiece_len is set)\n",
    "    word_embeddings = bert_model(input_ids, attention_mask=attention_mask).last_hidden_state\n",
    "    '''word_embeddings = tf.where(tf.math.equal(input_ids, pad_token_id), tf.zeros_like(word_embeddings), word_embeddings)  # Set padding to zero vectors\n",
    "    word_embeddings = tf.clip_by_value(word_embeddings, clip_value_min=0.0, clip_value_max=1.0)  # Clip for stability\n",
    "\n",
    "    # Truncate wordpieces to max_wordpiece_len (optional, adjust as needed)\n",
    "    if max_wordpiece_len:\n",
    "        word_embeddings = tf.sequence_mask(tokenizer.model_max_length, maxlen=max_wordpiece_len, dtype=tf.float32)[:, :, None] * word_embeddings\n",
    "\n",
    "    '''\n",
    "    return word_embeddings, input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ba443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode text data (including handling labels)\n",
    "text_embeddings_train_bert, train_ids = encode_sentences(train_df['text'])\n",
    "text_embeddings_train_bert = tf.where(tf.math.equal(input_ids, pad_token_id), tf.zeros_like(text_embeddings_train_bert), text_embeddings_train_bert)  # Set padding to zero vectors\n",
    "text_embeddings_train_bert = tf.clip_by_value(text_embeddings_train_bert, clip_value_min=0.0, clip_value_max=1.0)  # Clip for stability\n",
    "\n",
    "# Truncate wordpieces to max_wordpiece_len (optional, adjust as needed)\n",
    "if max_wordpiece_len:\n",
    "    text_embeddings_train_bert = tf.sequence_mask(tokenizer.model_max_length, maxlen=max_wordpiece_len, dtype=tf.float32)[:, :, None] * text_embeddings_train_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625d507c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode text data (including handling labels)\n",
    "text_embeddings_val_bert, val_ids = encode_sentences(val_df['text'])\n",
    "text_embeddings_val_bert = tf.where(tf.math.equal(input_ids, pad_token_id), tf.zeros_like(text_embeddings_val_bert), text_embeddings_val_bert)  \n",
    "text_embeddings_val_bert = tf.clip_by_value(text_embeddings_val_bert, clip_value_min=0.0, clip_value_max=1.0)  # Clip for stability\n",
    "\n",
    "# Truncate wordpieces to max_wordpiece_len (optional, adjust as needed)\n",
    "if max_wordpiece_len:\n",
    "    text_embeddings_val_bert = tf.sequence_mask(tokenizer.model_max_length, maxlen=max_wordpiece_len, dtype=tf.float32)[:, :, None] * text_embeddings_val_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cd8af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode text data (including handling labels)\n",
    "text_embeddings_test_bert, test_ids = encode_sentences(test_df['text'])\n",
    "\n",
    "text_embeddings_test_bert = tf.where(tf.math.equal(input_ids, pad_token_id), tf.zeros_like(text_embeddings_test_bert), text_embeddings_test_bert)  # Set padding to zero vectors\n",
    "text_embeddings_test_bert = tf.clip_by_value(text_embeddings_test_bert, clip_value_min=0.0, clip_value_max=1.0)  # Clip for stability\n",
    "\n",
    "# Truncate wordpieces to max_wordpiece_len (optional, adjust as needed)\n",
    "if max_wordpiece_len:\n",
    "    text_embeddings_test_bert = tf.sequence_mask(tokenizer.model_max_length, maxlen=max_wordpiece_len, dtype=tf.float32)[:, :, None] * text_embeddings_test_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb2ae44",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_embeddings_train_bert,strain_ids=encode_sentences(\n",
    "    train_df['summary'])  \n",
    "\n",
    "summary_embeddings_train_bert = tf.where(tf.math.equal(input_ids, pad_token_id), tf.zeros_like(summary_embeddings_train_bert), summary_embeddings_train_bert)  \n",
    "summary_embeddings_train_bert = tf.clip_by_value(summary_embeddings_train_bert, clip_value_min=0.0, clip_value_max=1.0)  # Clip for stability\n",
    "\n",
    "# Truncate wordpieces to max_wordpiece_len (optional, adjust as needed)\n",
    "if max_wordpiece_len:\n",
    "    summary_embeddings_train_bert = tf.sequence_mask(tokenizer.model_max_length, maxlen=max_wordpiece_len, dtype=tf.float32)[:, :, None] * summary_embeddings_train_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcd2658",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_embeddings_val_bert,sval_ids=encode_sentences(val_df['summary'])  \n",
    "\n",
    "summary_embeddings_val_bert = tf.where(tf.math.equal(input_ids, pad_token_id), tf.zeros_like(summary_embeddings_val_bert), summary_embeddings_val_bert)  \n",
    "summary_embeddings_val_bert = tf.clip_by_value(summary_embeddings_val_bert, clip_value_min=0.0, clip_value_max=1.0)  # Clip for stability\n",
    "\n",
    "# Truncate wordpieces to max_wordpiece_len (optional, adjust as needed)\n",
    "if max_wordpiece_len:\n",
    "    summary_embeddings_val_bert = tf.sequence_mask(tokenizer.model_max_length, maxlen=max_wordpiece_len, dtype=tf.float32)[:, :, None] * summary_embeddings_val_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a75876",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_embeddings_test_bert,stest_ids=encode_sentences(test_df['summary']) \n",
    "\n",
    "summary_embeddings_test_bert = tf.where(tf.math.equal(input_ids, pad_token_id), tf.zeros_like(summary_embeddings_test_bert), summary_embeddings_test_bert)  \n",
    "summary_embeddings_test_bert = tf.clip_by_value(summary_embeddings_test_bert, clip_value_min=0.0, clip_value_max=1.0)  # Clip for stability\n",
    "\n",
    "# Truncate wordpieces to max_wordpiece_len (optional, adjust as needed)\n",
    "if max_wordpiece_len:\n",
    "    summary_embeddings_test_bert = tf.sequence_mask(tokenizer.model_max_length, maxlen=max_wordpiece_len, dtype=tf.float32)[:, :, None] * summary_embeddings_test_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ee3452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5a58a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate one-hot encoded labels (modify based on your label format)\n",
    "def generate_labels(sentences, summaries):\n",
    "    labels = []\n",
    "    for sentence, summary in zip(sentences, summaries):\n",
    "        sentence_tokens = tokenizer.convert_ids_to_tokens(sentence)\n",
    "        summary_tokens = tokenizer.convert_ids_to_tokens(summary)\n",
    "        label = [1 if token in summary_tokens else 0 for token in sentence_tokens]\n",
    "        labels.append(label)\n",
    "    return np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b31c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = generate_labels(train_df['text'].tolist(), \n",
    "                               train_df['summary'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276d70cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = generate_labels(val_df['text'].tolist(),\n",
    "                             val_df['summary'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f532cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = generate_labels(test_df['text'].tolist(),\n",
    "                              test_df['summary'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba1e7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input shape for text embeddings and labels\n",
    "input_shape = (max_len_word, 768)\n",
    "label_shape = (max_len_word,)  # Adjust based on your label format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ab7dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dropout, Dense, Flatten\n",
    "from tensorflow.keras.layers import Concatenate, Lambda, LayerNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7d6ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input layers for text and labels\n",
    "text_input = Input(shape=input_shape)\n",
    "label_input = Input(shape=label_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c344bd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define layer groups (example structure with 12 groups)\n",
    "for _ in range(12):\n",
    "    # Self-attention layer\n",
    "    self_attention = tf.keras.layers.MultiHeadAttention(num_heads=8, key_dim=64)(\n",
    "    query=text_input, value=text_input, attention_mask=text_input)  # Use text_input for self-attention\n",
    "    self_attention = LayerNormalization()(self_attention + text_input)\n",
    "    self_attention = Dropout(0.1)(self_attention)\n",
    "\n",
    "    # Feed forward layer\n",
    "    feed_forward = Dense(200, activation='relu')(self_attention)\n",
    "    feed_forward = LayerNormalization()(feed_forward)\n",
    "    feed_forward = Dense(768)(feed_forward)\n",
    "    feed_forward = LayerNormalization()(feed_forward)\n",
    "    feed_forward = Dropout(0.1)(feed_forward)\n",
    "\n",
    "    # Update text embeddings\n",
    "    text_input = feed_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a617dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final layers for predicting deletion probability\n",
    "deletion_prob = Dense(1, activation=\"sigmoid\")(text_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedb65bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "model = Model(inputs=[text_input, label_input], outputs=deletion_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3049f13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss=binary_crossentropy,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbaa5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833dc4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model on training data\n",
    "model.fit([text_embeddings_train_bert, train_labels], train_labels,\n",
    "          validation_data=([text_embeddings_val_bert, val_labels], val_labels),\n",
    "          epochs=15, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26d83b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for prediction on unseen sentences (consider batching for efficiency)\n",
    "def predict_deletion_probs(sentence):\n",
    "  # Encode the sentence\n",
    "  sentence_embeddings, _ = encode_sentences([sentence])\n",
    "\n",
    "  # Predict deletion probabilities\n",
    "  deletion_probs = model.predict([sentence_embeddings])[0]  # Access the first element for single sentence\n",
    "\n",
    "  # Return deletion probabilities\n",
    "  return deletion_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042b5e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage (assuming you have a sentence)\n",
    "sentence = \" A mariachi band has serenaded Donald Trump on the sidewalk outside Trump Tower in New York City.\"\n",
    "deletion_probs = predict_deletion_probs(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330b89fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process deletion probabilities to generate the compressed sentence (logic based on your needs)\n",
    "compressed_sentence = \"\"\n",
    "for i, prob in enumerate(deletion_probs):\n",
    "    if prob > 0.5:  # Adjust threshold as needed\n",
    "        compressed_sentence += tokenizer.convert_ids_to_tokens(text_embeddings_train_bert[0][i].numpy())[0] + \" \"  # Access word from embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76af57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Original Sentence: {sentence}\")\n",
    "print(f\"Compressed Sentence: {compressed_sentence.strip()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8894a19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c797379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f21133",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7d6ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e72188f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049b7ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114fcd17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2983e76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cef0c57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126564df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7efaf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178da85e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5de413",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc91305",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4693be3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf0e335",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
